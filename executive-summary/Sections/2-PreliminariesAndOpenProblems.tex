\section{Preliminaries and Problems}
\label{sec:preliminaries_and_open_problems}

In the Edge Computing paradigm, computing and storage nodes are placed at the Internetâ€™s edge in close proximity to mobile devices or IoT sensors, so "edge" can be considered any computing and network resources along the path \textbf{between data sources and cloud data centers}.
The origin of Edge Computing dates back to the late 1990s when Content Delivery Networks (CDNs) were introduced to increase web performance \cite{edge-computing-origin}. A CDN uses machines at the edge of the network to cache frequently requested contents, allowing to save bandwidth and improve the latency. Edge computing generalizes and extends the CDN concept with the goal of moving core-centric applications to a geo-distributed environment as in an edge network.

Edge Computing can address many concerns like response time requirements, mobile devices' limited battery life, as well as bandwidth cost saving \cite{emergence-edge-computing}.

An \textbf{improved latency} can be provided thanks to the proximity between the edge server and the client that allows to avoid the travel-distance needed to make the client communicate to the central cloud platform.

Mobile devices' \textbf{battery life} can be saved by offloading the computation to the nearest edge server, instead of computing it locally. This is particularly useful for battery powered IoT sensors or other devices stringently limited in power.

And ultimately \textbf{bandwidth costs} can be saved thanks to reduced usage of the network and by allowing to run compression techniques directly at the edge near the client.


\subsection{Data Processing}
Data processing on the edge is clearly a field in development, many different ideas are being presented with innovative concepts.

In several papers it is applied the concept of \textbf{stream processing}, a branch of data processing in which \textbf{long-running operators} are placed in the network and data is bound to be flowing through these operators.
At the "IEEE International Conference on Fog and Edge Computing (ICFEC)" a few pioneering solutions were presented in which it has been shown how to find the best deployment on an edge infrastructure \cite{how-to-deploy-fog-applications} \cite{optimal-placement-stream} and how to dynamically choose which node can process the data stream \cite{data-driven-stream}.

A recurring topic is also the management of \textbf{less abundant resources}, which is for sure a clear distinction in respect to a classic core-centric infrastructure. At the ICFEC there were presented solutions for using both the storage \cite{efficient-edge-storage} and the bandwidth \cite{virtual-events-edge} efficiently.

An important concept is also the one of serverless execution. Nastic et al.~\cite{serverless-analytics-edge} expose how current approaches for data analytics on the edge force developers to resort to processes that are largely manual, task-specific, and error-prone. They defined the main prerequisites and the architecture of a platform which can allow data processing and analytics on the edge while abstracting the complexity of the edge infrastructure. Some of their concepts are the main inspiration behind our work.


\subsection{Edge Applications}

During our research we collected and organized the high-level applications and the more specific use cases, which have been used to motivate the work done by the research in the field of data processing on the edge.

A common characteristic present in all the applications is the \textbf{absence of the need for a fully global view}. If a global view is needed, of course a core-centric approach would be preferred since with all the information in one point it becomes easier to create a result that collects all the information.

Instead the applications usually present a dependency with a \textbf{user} (e.g., \textit{Wearable healthcare devices}, \textit{Online shopping cart}), a \textbf{device} (e.g., \textit{Connected vehicles}, \textit{Surveillance footage analysis}) or a \textbf{geographical area} (e.g., \textit{Smart home}, \textit{Smart city}, \textit{Building environment control}).

Some of the applications necessarily need a \textbf{state} (e.g., \textit{Massively multiplayer online games}, \textit{Online shopping cart}) while a few may not need it (e.g., \textit{Surveillance footage analysis}).

We also see a clear difference between applications that have a \textbf{static approach to changes of location} and applications that instead are \textbf{dynamic in changes}. For example \textit{Wearable healthcare devices} is for sure a dynamic application where the person wearing the device can change location frequently, while the \textit{Building environment control} application is clearly static in changes.

And finally we noticed how these applications all have the need of a \textbf{high write throughput}, they do not have a clear predominance of read actions with reference to write actions. In fact applications with high read and low write throughput can be already fulfilled by Content Delivery Networks or similar solutions.


\subsection{Edge Use Cases}

The usage of the edge, in many of the use cases we collected, has been motivated by the research with the goal of \textbf{bandwidth reduction}.

A recurring motivation is also the \textbf{location awareness} which comes for free when working on the edge of the network. The location awareness feature can be used in interesting use cases like finding trending topics of a certain area in a social network or analyzing video footage to monitor the traffic in a certain road.
